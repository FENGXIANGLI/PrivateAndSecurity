{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [-0.9999969] b: [0.9999908] loss: 5.6999738e-11\n",
      "W: [-0.8397583] b: [0.52886957] loss: 0.14828278\n",
      "W: [nan] b: [nan] loss: nan\n",
      "W: [nan] b: [nan] loss: nan\n",
      "All the result\n",
      "[{'learningRate': 0.01, 'loss': 5.6999738e-11}, {'learningRate': 0.001, 'loss': 0.14828278}, {'learningRate': 0.1, 'loss': nan}, {'learningRate': 0.5, 'loss': nan}]\n"
     ]
    }
   ],
   "source": [
    "# part 2\n",
    "import tensorflow as tf\n",
    "# Model parameters\n",
    "def trainWithLearningRate(learning_rate):\n",
    "    W = tf.Variable([.3], dtype=tf.float32)\n",
    "    b = tf.Variable([-.3], dtype=tf.float32)\n",
    "    # Model input and output\n",
    "    x = tf.placeholder(tf.float32)\n",
    "    linear_model = W*x + b\n",
    "    y = tf.placeholder(tf.float32)\n",
    "    # loss\n",
    "    loss = tf.reduce_sum(tf.square(linear_model - y)) # sum of the squares\n",
    "    # optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    train = optimizer.minimize(loss)\n",
    "    # training data\n",
    "    x_train = [1, 2, 3, 4]\n",
    "    y_train = [0, -1, -2, -3]\n",
    "    # training loop\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init) # reset values to wrong\n",
    "    for i in range(1000):\n",
    "      sess.run(train, {x: x_train, y: y_train})\n",
    "    # evaluate training accuracy\n",
    "    curr_W, curr_b, curr_loss = sess.run([W, b, loss], {x: x_train, y: y_train})\n",
    "    \n",
    "    print(\"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))\n",
    "    return {\"learningRate\": learning_rate,\"loss\": curr_loss}\n",
    "\n",
    "learning_rates = [0.01,0.001,0.1,0.5]\n",
    "\n",
    "result = []\n",
    "for learning_rate in learning_rates:\n",
    "    result.append(trainWithLearningRate(learning_rate))\n",
    "\n",
    "print(\"All the result\")\n",
    "print(result)\n",
    "\n",
    "# The best learning rate is 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
      "0.8714\n",
      "0.91\n",
      "0.9187\n",
      "0.9179\n",
      "0.9167\n",
      "[{'learning_rate': 0.01, 'Accuracy': 0.8714}, {'learning_rate': 0.1, 'Accuracy': 0.91}, {'learning_rate': 0.3, 'Accuracy': 0.9187}, {'learning_rate': 0.5, 'Accuracy': 0.9179}, {'learning_rate': 0.7, 'Accuracy': 0.9167}]\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifengxiang/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2870: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# part 3\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "def mnistWithLearningRate(mnist,learning_rate):\n",
    "  # Create the model\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    W = tf.Variable(tf.zeros([784, 10]))\n",
    "    b = tf.Variable(tf.zeros([10]))\n",
    "    y = tf.matmul(x, W) + b\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "    # The raw formulation of cross-entropy,\n",
    "    #\n",
    "    #   tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.nn.softmax(y)),\n",
    "    #                                 reduction_indices=[1]))\n",
    "    #\n",
    "    # can be numerically unstable.\n",
    "    #\n",
    "    # So here we use tf.nn.softmax_cross_entropy_with_logits on the raw\n",
    "    # outputs of 'y', and then average across the batch.\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    tf.global_variables_initializer().run()\n",
    "    # Train\n",
    "    for _ in range(1000):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "        sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "    # Test trained model\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    accuracy = sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
    "                                      y_: mnist.test.labels})\n",
    "    print(accuracy)\n",
    "    return {\"learning_rate\": learning_rate, \"Accuracy\": accuracy}\n",
    "    \n",
    "\n",
    "def main(_):\n",
    "  # Import data\n",
    "    mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)\n",
    "    learning_rates = [0.01,0.1,0.3,0.5,0.7]\n",
    "    result = []\n",
    "    for rate in learning_rates:\n",
    "        result.append(mnistWithLearningRate(mnist,rate))\n",
    "    print(result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data_dir', type=str, default='/tmp/tensorflow/mnist/input_data',\n",
    "                      help='Directory for storing input data')\n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n",
      "batch size is 5 mode is Sequential\n",
      "0.8549\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n",
      "batch size is 10 mode is Sequential\n",
      "0.854\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n",
      "batch size is 50 mode is Sequential\n",
      "0.9135\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n",
      "batch size is 5 mode is Random\n",
      "0.6466\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n",
      "batch size is 10 mode is Random\n",
      "0.8248\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n",
      "batch size is 50 mode is Random\n",
      "0.8376\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n",
      "batch size is 5 mode is Maximum\n",
      "0.4634\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n",
      "batch size is 10 mode is Maximum\n",
      "0.5063\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n",
      "batch size is 50 mode is Maximum\n",
      "0.6026\n",
      "[{'N': 5, 'Mode': 'Sequential', 'Accuracy': 0.8549}, {'N': 10, 'Mode': 'Sequential', 'Accuracy': 0.854}, {'N': 50, 'Mode': 'Sequential', 'Accuracy': 0.9135}, {'N': 5, 'Mode': 'Random', 'Accuracy': 0.6466}, {'N': 10, 'Mode': 'Random', 'Accuracy': 0.8248}, {'N': 50, 'Mode': 'Random', 'Accuracy': 0.8376}, {'N': 5, 'Mode': 'Maximum', 'Accuracy': 0.4634}, {'N': 10, 'Mode': 'Maximum', 'Accuracy': 0.5063}, {'N': 50, 'Mode': 'Maximum', 'Accuracy': 0.6026}]\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifengxiang/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2870: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# part 4\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import numpy\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "def mnistWithLearningRate(N,mode):\n",
    "  # Create the model\n",
    "    mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    W = tf.Variable(tf.zeros([784, 10]))\n",
    "    b = tf.Variable(tf.zeros([10]))\n",
    "    y = tf.matmul(x, W) + b\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "    # The raw formulation of cross-entropy,\n",
    "    #\n",
    "    #   tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.nn.softmax(y)),\n",
    "    #                                 reduction_indices=[1]))\n",
    "    #\n",
    "    # can be numerically unstable.\n",
    "    #\n",
    "    # So here we use tf.nn.softmax_cross_entropy_with_logits on the raw\n",
    "    # outputs of 'y', and then average across the batch.\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    tf.global_variables_initializer().run()\n",
    "    # Train\n",
    "\n",
    "    for i in range(1000):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "        if (i + 1) % N == 0:\n",
    "            if mode == \"Sequential\":\n",
    "                numpy.random.shuffle(batch_ys)\n",
    "            elif mode == \"Random\":\n",
    "                m,n = batch_ys.shape\n",
    "                for i in range(m):\n",
    "                    randomCol = np.random.randint(10)\n",
    "                    while batch_ys[i][randomCol] == 1:\n",
    "                        randomCol = np.random.randint(10)\n",
    "                    batch_ys[i] = np.zeros(10)\n",
    "                    batch_ys[i][randomCol] = 1\n",
    "\n",
    "            elif mode == \"Maximum\":\n",
    "                m,n = batch_ys.shape\n",
    "                for i in range(m):\n",
    "                    if batch_ys[i][0] == 1:\n",
    "                        batch_ys[i][0] = 0\n",
    "                        batch_ys[i][6] = 1\n",
    "                    elif batch_ys[i][1] == 1:\n",
    "                        batch_ys[i][1] = 0\n",
    "                        batch_ys[i][7] = 1\n",
    "                    elif batch_ys[i][2] == 1:\n",
    "                        batch_ys[i][2] = 0\n",
    "                        batch_ys[i][5] = 1\n",
    "                    elif batch_ys[i][3] == 1:\n",
    "                        batch_ys[i][3] = 0\n",
    "                        batch_ys[i][8] = 1\n",
    "                    elif batch_ys[i][4] == 1:\n",
    "                        batch_ys[i][4] = 0\n",
    "                        batch_ys[i][9] = 1\n",
    "        \n",
    "        sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "    # Test trained model\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    accuarcy = sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
    "                                      y_: mnist.test.labels})\n",
    "    print(\"\\n\")\n",
    "    print(\"batch size is \" + str(N) , \"mode is \" + mode)\n",
    "    accuracy = sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
    "                                      y_: mnist.test.labels})\n",
    "    print(accuracy)\n",
    "    return {\"N\": N,\"Mode\": mode,\"Accuracy\": accuracy}\n",
    "    \n",
    "def main(_):\n",
    "  # Import data\n",
    "    \n",
    "    batch_sizes = [5,10,50]\n",
    "    modes = [\"Sequential\",\"Random\",\"Maximum\"]\n",
    "\n",
    "    result = []\n",
    "    for mode in modes:\n",
    "        for batch_size in batch_sizes:\n",
    "            result.append(mnistWithLearningRate(batch_size,mode))\n",
    "    print(result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data_dir', type=str, default='/tmp/tensorflow/mnist/input_data',\n",
    "                      help='Directory for storing input data')\n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
